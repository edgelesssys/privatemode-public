apiVersion: apps/v1
kind: Deployment
metadata:
  name: secret-service
  namespace: continuum-75947b
  labels:
    app.kubernetes.io/instance: '75947b'
spec:
  replicas: 1
  selector:
    matchLabels:
      app: secret-service
  template:
    metadata:
      labels:
        app: secret-service
        app.kubernetes.io/instance: '75947b'
    spec:
      runtimeClassName: contrast-cc
      containers:
        - name: secret-service
          image: 'ghcr.io/edgelesssys/privatemode/secret-service:v1.11.0@sha256:327a3f8cc72af952a7b8eb1079bf56421d58563575d62bac2afd9d517dc1a774'
          args:
            - '--etcd-cert-sans=secret-service-internal.continuum-75947b.svc.cluster.local'
          ports:
            - containerPort: 3000
            - containerPort: 3001
            - containerPort: 9000
            - containerPort: 2379
            - containerPort: 2380
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: workload-codegen
  namespace: continuum-75947b
  labels:
    app: workload-codegen
    app.kubernetes.io/instance: '75947b'
spec:
  replicas: 1
  selector:
    matchLabels:
      app: workload-codegen
  serviceName: workload-codegen
  template:
    metadata:
      labels:
        app: workload-codegen
        app.kubernetes.io/instance: '75947b'
        privatemode.edgeless.systems/needs-gpu: "true"
      annotations:
        io.katacontainers.config.hypervisor.default_memory: "64000"
        io.katacontainers.config.runtime.create_container_timeout: "1800"
    spec:
      serviceAccountName: workload-codegen-sa
      runtimeClassName: contrast-cc
      initContainers:
        - name: attestation-agent
          image: ghcr.io/edgelesssys/privatemode/attestation-agent:v1.11.0@sha256:5d4f669ee8fc63fe2f6e9b33997c2bd6b78549fca2ea54933bb927ee9dd4c727
          env:
            - name: NVIDIA_VISIBLE_DEVICES
              value: "all"
          command:
            - '/bin/sh'
            - '-c'
          args:
            - |
              ln -sf /usr/lib64/libnvidia-ml.so.550.90.07 /usr/lib64/libnvidia-ml.so.1 && \
              LD_PRELOAD=/usr/lib64/libcuda.so.1:usr/lib64/libnvidia-ml.so.1 attestation-agent \
                --secret-svc-address=secret-service-internal.continuum-75947b.svc.cluster.local \
                --gpu-debug=false \
                --gpu-secure-boot=true \
                --gpu-eat-version=EAT-21 \
                --gpu-driver-versions=535.104.05,535.129.03,550.90.07 \
                --gpu-vbios-versions=96.00.88.00.11,96.00.74.00.11,96.00.9F.00.04,96.00.74.00.1C
          securityContext:
            privileged: true
          volumeMounts:
            - name: etcd-pki
              mountPath: /var/run/continuum/etcd/pki
            - mountPath: /contrast
              name: contrast-secrets
          resources:
            limits:
              "nvidia.com/GH100_H100_PCIE": 1
        - name: disk-mounter
          image: ghcr.io/edgelesssys/privatemode/disk-mounter:v1.11.0@sha256:f70568730d13a92f2a390f571381dcdaf3e48e3ca60e30bd460dda92e34d03e0
          args:
            - --root-hash=c6ab549d3ec1cb75d531886229825deec19e43e1dbc35480fd82a0517f04c14c
            - --device-path=/dev/modelweights
            - --mount-path=/mnt/modelweights
          restartPolicy: Always
          securityContext:
            privileged: true
          volumeMounts:
            - name: mount-dir
              mountPath: /mnt
              mountPropagation: Bidirectional
            - name: etcd-pki
              mountPath: /var/run/continuum/etcd/pki
          volumeDevices:
            - name: modelweights
              devicePath: /dev/modelweights
      containers:
        - name: workload
          image: docker.io/vllm/vllm-openai:v0.7.3@sha256:4f4037303e8c7b69439db1077bb849a0823517c0f785b894dc8e96d58ef3a0c2
          ports:
            - containerPort: 8000
          readinessProbe:
            httpGet:
              path: /v1/models
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 60
          env:
            - name: NVIDIA_VISIBLE_DEVICES
              value: "all"
            - name: LD_PRELOAD
              value: "/usr/lib/x86_64-linux-gnu/libcuda.so.1"
          args:
            - '--host=0.0.0.0'
            - '--model=/mnt/modelweights'
            - '--served-model-name'
            - 'mistralai/Codestral-22B-v0.1'
            - '--disable-log-requests'
          volumeMounts:
            - name: mount-dir
              mountPath: /mnt
              mountPropagation: HostToContainer
          resources:
            limits:
              "nvidia.com/GH100_H100_PCIE": 1
        - name: inference-proxy
          image: ghcr.io/edgelesssys/privatemode/inference-proxy:v1.11.0@sha256:9a06ae135ce75c705a2897a269c2e4d17e86f744e92846da76222eaa99e9ed8a
          ports:
            - containerPort: 8085
          args:
            - --adapter-type=openai
            - --workload-address=127.0.0.1
            - --workload-port=8000
            - --secret-svc-address=secret-service-internal.continuum-75947b.svc.cluster.local
          volumeMounts:
            - name: etcd-pki
              mountPath: /var/run/continuum/etcd/pki
      volumes:
        - emptyDir: {}
          name: mount-dir
        - name: etcd-pki
          emptyDir: {}
  volumeClaimTemplates:
    - kind: PersistentVolumeClaim
      metadata:
        name: modelweights
        labels:
          app.kubernetes.io/instance: '75947b'
      spec:
        storageClassName: mistralai-codestral-22b-v0-1
        volumeMode: Block
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: 46Gi
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: workload-textgen
  namespace: continuum-75947b
  labels:
    app: workload-textgen
    app.kubernetes.io/instance: '75947b'
spec:
  replicas: 1
  selector:
    matchLabels:
      app: workload-textgen
  serviceName: workload-textgen
  template:
    metadata:
      labels:
        app: workload-textgen
        app.kubernetes.io/instance: '75947b'
        privatemode.edgeless.systems/needs-gpu: "true"
      annotations:
        io.katacontainers.config.hypervisor.default_memory: "64000"
        io.katacontainers.config.runtime.create_container_timeout: "1800"
    spec:
      serviceAccountName: workload-textgen-sa
      runtimeClassName: contrast-cc
      initContainers:
        - name: attestation-agent
          image: ghcr.io/edgelesssys/privatemode/attestation-agent:v1.11.0@sha256:5d4f669ee8fc63fe2f6e9b33997c2bd6b78549fca2ea54933bb927ee9dd4c727
          env:
            - name: NVIDIA_VISIBLE_DEVICES
              value: "all"
          command:
            - '/bin/sh'
            - '-c'
          args:
            - |
              ln -sf /usr/lib64/libnvidia-ml.so.550.90.07 /usr/lib64/libnvidia-ml.so.1 && \
              LD_PRELOAD=/usr/lib64/libcuda.so.1:usr/lib64/libnvidia-ml.so.1 attestation-agent \
                --secret-svc-address=secret-service-internal.continuum-75947b.svc.cluster.local \
                --gpu-debug=false \
                --gpu-secure-boot=true \
                --gpu-eat-version=EAT-21 \
                --gpu-driver-versions=535.104.05,535.129.03,550.90.07 \
                --gpu-vbios-versions=96.00.88.00.11,96.00.74.00.11,96.00.9F.00.04,96.00.74.00.1C
          securityContext:
            privileged: true
          volumeMounts:
            - name: etcd-pki
              mountPath: /var/run/continuum/etcd/pki
            - mountPath: /contrast
              name: contrast-secrets
          resources:
            limits:
              "nvidia.com/GH100_H100_PCIE": 1
        - name: disk-mounter
          image: ghcr.io/edgelesssys/privatemode/disk-mounter:v1.11.0@sha256:f70568730d13a92f2a390f571381dcdaf3e48e3ca60e30bd460dda92e34d03e0
          args:
            - --root-hash=3a49ed30e4a637228b5d962c6b1fa508bad337ca73ef02cb9f0dcc7931fefad7
            - --device-path=/dev/modelweights
            - --mount-path=/mnt/modelweights
          restartPolicy: Always
          securityContext:
            privileged: true
          volumeMounts:
            - name: mount-dir
              mountPath: /mnt
              mountPropagation: Bidirectional
            - name: etcd-pki
              mountPath: /var/run/continuum/etcd/pki
          volumeDevices:
            - name: modelweights
              devicePath: /dev/modelweights
      containers:
        - name: workload
          image: docker.io/vllm/vllm-openai:v0.7.3@sha256:4f4037303e8c7b69439db1077bb849a0823517c0f785b894dc8e96d58ef3a0c2
          ports:
            - containerPort: 8000
          readinessProbe:
            httpGet:
              path: /v1/models
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 60
          env:
            - name: NVIDIA_VISIBLE_DEVICES
              value: "all"
            - name: LD_PRELOAD
              value: "/usr/lib/x86_64-linux-gnu/libcuda.so.1"
          args:
            - '--host=0.0.0.0'
            - '--model=/mnt/modelweights'
            - '--served-model-name'
            - 'ibnzterrell/Meta-Llama-3.3-70B-Instruct-AWQ-INT4'
            - 'latest'
            - '--disable-log-requests'
            - '--max-model-len=70000'
            - '--enable-auto-tool-choice'
            - '--tool-call-parser'
            - 'llama3_json'
          volumeMounts:
            - name: mount-dir
              mountPath: /mnt
              mountPropagation: HostToContainer
          resources:
            limits:
              "nvidia.com/GH100_H100_PCIE": 1
        - name: inference-proxy
          image: ghcr.io/edgelesssys/privatemode/inference-proxy:v1.11.0@sha256:9a06ae135ce75c705a2897a269c2e4d17e86f744e92846da76222eaa99e9ed8a
          ports:
            - containerPort: 8085
          args:
            - --adapter-type=openai
            - --workload-address=127.0.0.1
            - --workload-port=8000
            - --secret-svc-address=secret-service-internal.continuum-75947b.svc.cluster.local
          volumeMounts:
            - name: etcd-pki
              mountPath: /var/run/continuum/etcd/pki
      volumes:
        - emptyDir: {}
          name: mount-dir
        - name: etcd-pki
          emptyDir: {}
  volumeClaimTemplates:
    - kind: PersistentVolumeClaim
      metadata:
        name: modelweights
        labels:
          app.kubernetes.io/instance: '75947b'
      spec:
        storageClassName: ibnzterrell-meta-llama-3-3-70b-instruct-awq-int4
        volumeMode: Block
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: 41Gi
